{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a9097cc-3d93-47c4-afe3-45621db3c69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found families:\n",
      "- AESCrypt\n",
      "- Conti\n",
      "- Darkside\n",
      "- Firefox\n",
      "- Idle\n",
      "- LockBit\n",
      "- Office\n",
      "- REvil\n",
      "- Ryuk\n",
      "- SDelete\n",
      "- WannaCry\n",
      "- Zip\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATASET_PATH = \"../Datasets/RanSMAP/dataset/original/i3-gen12/ddr4-3200-16g\"\n",
    "PROCESSED_PATH = \"../Datasets/Processed\"\n",
    "os.makedirs(PROCESSED_PATH, exist_ok=True)\n",
    "\n",
    "families = sorted([\n",
    "    f for f in os.listdir(DATASET_PATH)\n",
    "    if os.path.isdir(os.path.join(DATASET_PATH, f))\n",
    "])\n",
    "\n",
    "print(\"Found families:\")\n",
    "for f in families:\n",
    "    print(\"-\", f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303c4d62-d030-48c9-b3f7-6d986f6e8bbb",
   "metadata": {},
   "source": [
    "## Dataset Structure and Combination Plan\n",
    "\n",
    "Each run in the dataset consists of six CSV files recording different types of storage and memory access operations: ata_read.csv, ata_write.csv, mem_read.csv, mem_write.csv, mem_readwrite.csv, and mem_exec.csv. These files log detailed events such as timestamps, accessed addresses, access sizes, entropy, and access types. Storage access logs (ata_read and ata_write) capture disk-related activities, while the memory access logs (mem_read, mem_write, mem_readwrite, and mem_exec) reflect RAM usage and execution behavior.\n",
    "\n",
    "Each record in these files includes essential columns like the UNIX timestamp (seconds and nanoseconds), address (LBA for storage, GPA for memory), size of the accessed block or page, entropy (when applicable), and type (for memory page classification). Entropy values are meaningful indicators, especially for write operations, as they can reveal patterns related to ransomware encryption activities.\n",
    "\n",
    "Rather than merging these files line-by-line, we will summarize them into fixed-length feature vectors. Using a sliding window of 0.1 seconds, we will aggregate all access events within each window. For storage, we will calculate five features: read/write throughput, variance of accessed addresses during read/write, and average entropy of writes. For memory, we will generate eighteen features, capturing metrics like entropy (for write and read/write), counts of accessed pages (4KiB, 2MiB, MMIO), and variance of accessed physical addresses.\n",
    "\n",
    "Each 0.1-second window will become a single row in the final dataset, combining these 23 features along with metadata like timestamp and class label. This aggregated dataset will serve as the input for training and evaluating our AI models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27e21df6-88fd-4534-8cec-41749185f305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined CSV file structure and column names.\n"
     ]
    }
   ],
   "source": [
    "csv_files = {\n",
    "    \"ata_read.csv\": [\"ts\", \"tns\", \"lba\", \"size\", \"entropy_flag\", \"padding_flag\"],\n",
    "    \"ata_write.csv\": [\"ts\", \"tns\", \"lba\", \"size\", \"entropy\", \"padding_flag\"],\n",
    "    \"mem_read.csv\": [\"ts\", \"tns\", \"gpa\", \"size_flag\", \"entropy_flag\", \"type\"],\n",
    "    \"mem_write.csv\": [\"ts\", \"tns\", \"gpa\", \"size\", \"entropy\", \"type\"],\n",
    "    \"mem_readwrite.csv\": [\"ts\", \"tns\", \"gpa\", \"size\", \"entropy\", \"type\"],\n",
    "    \"mem_exec.csv\": [\"ts\", \"tns\", \"gpa\", \"size_flag\", \"entropy_flag\", \"type\"]\n",
    "}\n",
    "\n",
    "print(\"Defined CSV file structure and column names.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fd3a38c-49d2-4553-8d31-35985239016e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing family: AESCrypt (10 runs)\n",
      "  -> Processing run: AESCrypt-20220916_21-19-09\n",
      "  -> Processing run: AESCrypt-20220916_21-28-24\n",
      "  -> Processing run: AESCrypt-20220916_21-37-57\n",
      "  -> Processing run: AESCrypt-20220916_22-18-51\n",
      "  -> Processing run: AESCrypt-20220916_22-28-20\n",
      "  -> Processing run: AESCrypt-20220916_22-55-31\n",
      "  -> Processing run: AESCrypt-20220916_23-17-06\n",
      "  -> Processing run: AESCrypt-20220917_00-24-17\n",
      "  -> Processing run: AESCrypt-20220917_00-57-28\n",
      "  -> Processing run: AESCrypt-20220917_01-13-28\n",
      "Saved 19557 windows to ../Datasets/Processed/AESCrypt.parquet\n",
      "\n",
      "Processing family: Conti (10 runs)\n",
      "  -> Processing run: Conti-20220928_20-37-23\n",
      "  -> Processing run: Conti-20220928_20-52-48\n",
      "  -> Processing run: Conti-20220928_21-01-49\n",
      "  -> Processing run: Conti-20220928_21-10-36\n",
      "  -> Processing run: Conti-20220928_21-19-04\n",
      "  -> Processing run: Conti-20220928_21-26-38\n",
      "  -> Processing run: Conti-20220928_21-34-36\n",
      "  -> Processing run: Conti-20220928_22-59-15\n",
      "  -> Processing run: Conti-20220928_23-07-01\n",
      "  -> Processing run: Conti-20220928_23-14-59\n",
      "Saved 17739 windows to ../Datasets/Processed/Conti.parquet\n",
      "\n",
      "Processing family: Darkside (10 runs)\n",
      "  -> Processing run: Darkside-20230419_23-30-29\n",
      "  -> Processing run: Darkside-20230419_23-38-55\n",
      "  -> Processing run: Darkside-20230419_23-46-49\n",
      "  -> Processing run: Darkside-20230419_23-54-31\n",
      "  -> Processing run: Darkside-20230420_00-02-22\n",
      "  -> Processing run: Darkside-20230420_22-53-32\n",
      "  -> Processing run: Darkside-20230420_23-02-21\n",
      "  -> Processing run: Darkside-20230420_23-10-02\n",
      "  -> Processing run: Darkside-20230420_23-17-46\n",
      "  -> Processing run: Darkside-20230420_23-24-50\n",
      "Saved 16771 windows to ../Datasets/Processed/Darkside.parquet\n",
      "\n",
      "Processing family: Firefox (10 runs)\n",
      "  -> Processing run: Firefox-20221005_22-45-11\n",
      "  -> Processing run: Firefox-20221005_22-52-02\n",
      "  -> Processing run: Firefox-20221005_22-58-23\n",
      "  -> Processing run: Firefox-20221005_23-04-48\n",
      "  -> Processing run: Firefox-20221005_23-11-11\n",
      "  -> Processing run: Firefox-20221005_23-19-04\n",
      "  -> Processing run: Firefox-20221005_23-25-43\n",
      "  -> Processing run: Firefox-20221005_23-32-02\n",
      "  -> Processing run: Firefox-20221005_23-38-12\n",
      "  -> Processing run: Firefox-20221005_23-44-44\n",
      "Saved 10042 windows to ../Datasets/Processed/Firefox.parquet\n",
      "\n",
      "Processing family: Idle (10 runs)\n",
      "  -> Processing run: Idle-20230126_23-21-24\n",
      "  -> Processing run: Idle-20230126_23-27-29\n",
      "  -> Processing run: Idle-20230126_23-37-49\n",
      "  -> Processing run: Idle-20230126_23-44-18\n",
      "  -> Processing run: Idle-20230126_23-50-18\n",
      "  -> Processing run: Idle-20230126_23-56-16\n",
      "  -> Processing run: Idle-20230127_00-02-43\n",
      "  -> Processing run: Idle-20230127_00-09-34\n",
      "  -> Processing run: Idle-20230127_00-15-50\n",
      "  -> Processing run: Idle-20230127_00-22-28\n",
      "Saved 6189 windows to ../Datasets/Processed/Idle.parquet\n",
      "\n",
      "Processing family: LockBit (10 runs)\n",
      "  -> Processing run: LockBit-20220928_23-32-13\n",
      "  -> Processing run: LockBit-20220928_23-55-36\n",
      "  -> Processing run: LockBit-20220929_00-03-13\n",
      "  -> Processing run: LockBit-20220929_22-41-39\n",
      "  -> Processing run: LockBit-20220929_22-49-11\n",
      "  -> Processing run: LockBit-20220929_23-02-54\n",
      "  -> Processing run: LockBit-20220929_23-11-01\n",
      "  -> Processing run: LockBit-20220929_23-18-46\n",
      "  -> Processing run: LockBit-20220929_23-29-39\n",
      "  -> Processing run: LockBit-20220929_23-37-29\n",
      "Saved 18093 windows to ../Datasets/Processed/LockBit.parquet\n",
      "\n",
      "Processing family: Office (10 runs)\n",
      "  -> Processing run: Office-20221006_21-04-51\n",
      "  -> Processing run: Office-20221006_21-12-13\n",
      "  -> Processing run: Office-20221006_21-19-16\n",
      "  -> Processing run: Office-20221006_21-26-08\n",
      "  -> Processing run: Office-20221006_21-33-18\n",
      "  -> Processing run: Office-20221006_22-39-37\n",
      "  -> Processing run: Office-20221006_22-46-20\n",
      "  -> Processing run: Office-20221006_22-52-40\n",
      "  -> Processing run: Office-20221006_22-59-13\n",
      "  -> Processing run: Office-20221006_23-06-10\n",
      "Saved 6465 windows to ../Datasets/Processed/Office.parquet\n",
      "\n",
      "Processing family: REvil (10 runs)\n",
      "  -> Processing run: REvil-20230421_01-29-52\n",
      "  -> Processing run: REvil-20230421_01-38-34\n",
      "  -> Processing run: REvil-20230426_20-17-59\n",
      "  -> Processing run: REvil-20230426_20-25-57\n",
      "  -> Processing run: REvil-20230426_20-33-48\n",
      "  -> Processing run: REvil-20230426_20-44-21\n",
      "  -> Processing run: REvil-20230426_20-53-11\n",
      "  -> Processing run: REvil-20230426_21-00-00\n",
      "  -> Processing run: REvil-20230426_21-07-18\n",
      "  -> Processing run: REvil-20230426_21-14-25\n",
      "Saved 15296 windows to ../Datasets/Processed/REvil.parquet\n",
      "\n",
      "Processing family: Ryuk (10 runs)\n",
      "  -> Processing run: Ryuk-20230420_23-38-57\n",
      "  -> Processing run: Ryuk-20230420_23-46-50\n",
      "  -> Processing run: Ryuk-20230420_23-55-01\n",
      "  -> Processing run: Ryuk-20230421_00-03-13\n",
      "  -> Processing run: Ryuk-20230421_00-10-43\n",
      "  -> Processing run: Ryuk-20230421_00-21-25\n",
      "  -> Processing run: Ryuk-20230421_00-30-11\n",
      "  -> Processing run: Ryuk-20230421_00-38-02\n",
      "  -> Processing run: Ryuk-20230421_00-51-00\n",
      "  -> Processing run: Ryuk-20230421_00-59-13\n",
      "Saved 10636 windows to ../Datasets/Processed/Ryuk.parquet\n",
      "\n",
      "Processing family: SDelete (10 runs)\n",
      "  -> Processing run: SDelete-20221005_20-32-18\n",
      "  -> Processing run: SDelete-20221005_20-43-50\n",
      "  -> Processing run: SDelete-20221005_20-56-09\n",
      "  -> Processing run: SDelete-20221005_21-07-23\n",
      "  -> Processing run: SDelete-20221005_21-19-16\n",
      "  -> Processing run: SDelete-20221005_21-29-59\n",
      "  -> Processing run: SDelete-20221005_21-41-39\n",
      "  -> Processing run: SDelete-20221005_21-53-42\n",
      "  -> Processing run: SDelete-20221005_22-06-22\n",
      "  -> Processing run: SDelete-20221005_22-26-51\n",
      "Saved 17332 windows to ../Datasets/Processed/SDelete.parquet\n",
      "\n",
      "Processing family: WannaCry (10 runs)\n",
      "  -> Processing run: WannaCry-20230419_20-42-03\n",
      "  -> Processing run: WannaCry-20230419_20-54-37\n",
      "  -> Processing run: WannaCry-20230419_21-03-06\n",
      "  -> Processing run: WannaCry-20230419_21-12-41\n",
      "  -> Processing run: WannaCry-20230419_21-22-07\n",
      "  -> Processing run: WannaCry-20230419_21-29-28\n",
      "  -> Processing run: WannaCry-20230419_22-42-25\n",
      "  -> Processing run: WannaCry-20230419_23-00-34\n",
      "  -> Processing run: WannaCry-20230419_23-09-30\n",
      "  -> Processing run: WannaCry-20230419_23-17-12\n",
      "Saved 14488 windows to ../Datasets/Processed/WannaCry.parquet\n",
      "\n",
      "Processing family: Zip (10 runs)\n",
      "  -> Processing run: Zip-20220929_23-54-19\n",
      "  -> Processing run: Zip-20220930_00-01-30\n",
      "  -> Processing run: Zip-20220930_00-08-34\n",
      "  -> Processing run: Zip-20220930_00-16-12\n",
      "  -> Processing run: Zip-20220930_00-22-49\n",
      "  -> Processing run: Zip-20220930_00-29-44\n",
      "  -> Processing run: Zip-20220930_00-36-13\n",
      "  -> Processing run: Zip-20220930_00-42-17\n",
      "  -> Processing run: Zip-20220930_00-48-55\n",
      "  -> Processing run: Zip-20220930_00-55-09\n",
      "Saved 18295 windows to ../Datasets/Processed/Zip.parquet\n"
     ]
    }
   ],
   "source": [
    "WINDOW_SIZE = 0.1  # seconds\n",
    "\n",
    "for family in families:\n",
    "    family_path = os.path.join(DATASET_PATH, family)\n",
    "    runs = sorted([\n",
    "        r for r in os.listdir(family_path)\n",
    "        if os.path.isdir(os.path.join(family_path, r))\n",
    "    ])\n",
    "\n",
    "    print(f\"\\nProcessing family: {family} ({len(runs)} runs)\")\n",
    "    family_rows = []\n",
    "\n",
    "    for run in runs:\n",
    "        run_path = os.path.join(family_path, run)\n",
    "        print(f\"  -> Processing run: {run}\")\n",
    "\n",
    "        run_dfs = []\n",
    "\n",
    "        for csv_file, colnames in csv_files.items():\n",
    "            file_path = os.path.join(run_path, csv_file)\n",
    "\n",
    "            if not os.path.exists(file_path):\n",
    "                continue\n",
    "\n",
    "            df = pd.read_csv(file_path, header=None, names=colnames)\n",
    "            df[\"op_type\"] = csv_file.replace(\".csv\", \"\")\n",
    "            df[\"family\"] = family\n",
    "            df[\"run\"] = run\n",
    "            run_dfs.append(df)\n",
    "\n",
    "        if not run_dfs:\n",
    "            continue\n",
    "\n",
    "        run_df = pd.concat(run_dfs, ignore_index=True)\n",
    "\n",
    "        run_df[\"time\"] = run_df[\"ts\"] + run_df[\"tns\"] * 1e-9\n",
    "        run_df[\"time\"] -= run_df[\"time\"].min()\n",
    "        run_df[\"window\"] = (run_df[\"time\"] // WINDOW_SIZE).astype(int)\n",
    "\n",
    "        for window_id, window_data in run_df.groupby(\"window\"):\n",
    "            row = {\"family\": family, \"run\": run, \"window_id\": window_id}\n",
    "\n",
    "            read = window_data[window_data[\"op_type\"] == \"ata_read\"]\n",
    "            row[\"read_throughput\"] = read[\"size\"].sum() / WINDOW_SIZE\n",
    "            row[\"read_lba_var\"] = read[\"lba\"].var(ddof=0) if not read.empty else 0\n",
    "\n",
    "            write = window_data[window_data[\"op_type\"] == \"ata_write\"]\n",
    "            row[\"write_throughput\"] = write[\"size\"].sum() / WINDOW_SIZE\n",
    "            row[\"write_lba_var\"] = write[\"lba\"].var(ddof=0) if not write.empty else 0\n",
    "            row[\"write_entropy\"] = write[write[\"entropy\"] >= 0][\"entropy\"].mean() if not write.empty else 0\n",
    "\n",
    "            for op in [\"mem_read\", \"mem_write\", \"mem_readwrite\", \"mem_exec\"]:\n",
    "                mem = window_data[window_data[\"op_type\"] == op]\n",
    "                prefix = op\n",
    "\n",
    "                if op in [\"mem_write\", \"mem_readwrite\"]:\n",
    "                    row[f\"{prefix}_entropy\"] = mem[mem[\"entropy\"] >= 0][\"entropy\"].mean() if not mem.empty else 0\n",
    "\n",
    "                for ptype, name in zip([0, 1, 2], [\"4k\", \"2m\", \"mmio\"]):\n",
    "                    row[f\"{prefix}_count_{name}\"] = (mem[\"type\"] == ptype).sum()\n",
    "\n",
    "                row[f\"{prefix}_gpa_var\"] = mem[\"gpa\"].var(ddof=0) if not mem.empty else 0\n",
    "\n",
    "            family_rows.append(row)\n",
    "\n",
    "    family_df = pd.DataFrame(family_rows)\n",
    "    save_path = os.path.join(PROCESSED_PATH, f\"{family}.parquet\")\n",
    "    family_df.to_parquet(save_path)\n",
    "\n",
    "    print(f\"Saved {family_df.shape[0]} windows to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48753b86-dd8b-4ccf-b43e-8fea2f3a1251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sample parquet: Idle.parquet\n",
      "Sample rows:\n",
      "     family                     run  window_id  read_throughput  read_lba_var  \\\n",
      "4438   Idle  Idle-20230127_00-09-34        253              0.0  0.000000e+00   \n",
      "2505   Idle  Idle-20230126_23-50-18        267       11243520.0  2.988809e+14   \n",
      "1739   Idle  Idle-20230126_23-37-49       1727              0.0  0.000000e+00   \n",
      "6106   Idle  Idle-20230127_00-22-28       1442              0.0  0.000000e+00   \n",
      "4221   Idle  Idle-20230127_00-02-43       1500              0.0  0.000000e+00   \n",
      "\n",
      "      write_throughput  write_lba_var  write_entropy  mem_read_count_4k  \\\n",
      "4438               0.0   0.000000e+00       0.000000                  0   \n",
      "2505               0.0   0.000000e+00       0.000000                  0   \n",
      "1739               0.0   0.000000e+00       0.000000                  0   \n",
      "6106         1802240.0   2.569133e+15       0.458199                  0   \n",
      "4221               0.0   0.000000e+00       0.000000                  0   \n",
      "\n",
      "      mem_read_count_2m  ...  mem_write_gpa_var  mem_readwrite_entropy  \\\n",
      "4438                  0  ...       3.195927e+18               0.000000   \n",
      "2505                  0  ...       5.791664e+16               0.805003   \n",
      "1739                  0  ...       1.362356e+08               0.000000   \n",
      "6106                  0  ...       1.271952e+05               0.000000   \n",
      "4221                  0  ...       1.362356e+08               0.000000   \n",
      "\n",
      "      mem_readwrite_count_4k  mem_readwrite_count_2m  \\\n",
      "4438                       0                       0   \n",
      "2505                       0                       0   \n",
      "1739                       0                       0   \n",
      "6106                       0                       0   \n",
      "4221                       0                       0   \n",
      "\n",
      "      mem_readwrite_count_mmio  mem_readwrite_gpa_var  mem_exec_count_4k  \\\n",
      "4438                         0                    0.0                  0   \n",
      "2505                         2            288320400.0                  0   \n",
      "1739                         0                    0.0                  0   \n",
      "6106                         0                    0.0                  0   \n",
      "4221                         0                    0.0                  0   \n",
      "\n",
      "      mem_exec_count_2m  mem_exec_count_mmio  mem_exec_gpa_var  \n",
      "4438                  0                    0               0.0  \n",
      "2505                  0                    0               0.0  \n",
      "1739                  0                    0               0.0  \n",
      "6106                  0                    0               0.0  \n",
      "4221                  0                    0               0.0  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "\n",
      "==== Columns ====\n",
      "- family\n",
      "- run\n",
      "- window_id\n",
      "- read_throughput\n",
      "- read_lba_var\n",
      "- write_throughput\n",
      "- write_lba_var\n",
      "- write_entropy\n",
      "- mem_read_count_4k\n",
      "- mem_read_count_2m\n",
      "- mem_read_count_mmio\n",
      "- mem_read_gpa_var\n",
      "- mem_write_entropy\n",
      "- mem_write_count_4k\n",
      "- mem_write_count_2m\n",
      "- mem_write_count_mmio\n",
      "- mem_write_gpa_var\n",
      "- mem_readwrite_entropy\n",
      "- mem_readwrite_count_4k\n",
      "- mem_readwrite_count_2m\n",
      "- mem_readwrite_count_mmio\n",
      "- mem_readwrite_gpa_var\n",
      "- mem_exec_count_4k\n",
      "- mem_exec_count_2m\n",
      "- mem_exec_count_mmio\n",
      "- mem_exec_gpa_var\n",
      "\n",
      "Total columns: 26\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "processed_files = [f for f in os.listdir(PROCESSED_PATH) if f.endswith(\".parquet\")]\n",
    "sample_file = random.choice(processed_files)\n",
    "\n",
    "print(\"Loading sample parquet:\", sample_file)\n",
    "\n",
    "df = pd.read_parquet(os.path.join(PROCESSED_PATH, sample_file))\n",
    "\n",
    "print(\"Sample rows:\")\n",
    "print(df.sample(5))\n",
    "\n",
    "print(\"\\n==== Columns ====\")\n",
    "for col in df.columns:\n",
    "    print(\"-\", col)\n",
    "\n",
    "print(\"\\nTotal columns:\", len(df.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3209da93-7604-4415-a1f4-7a0c5617b05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded AESCrypt.parquet → 19557 rows\n",
      "Loaded Conti.parquet → 17739 rows\n",
      "Loaded Darkside.parquet → 16771 rows\n",
      "Loaded Firefox.parquet → 10042 rows\n",
      "Loaded Idle.parquet → 6189 rows\n",
      "Loaded LockBit.parquet → 18093 rows\n",
      "Loaded Office.parquet → 6465 rows\n",
      "Loaded REvil.parquet → 15296 rows\n",
      "Loaded Ryuk.parquet → 10636 rows\n",
      "Loaded SDelete.parquet → 17332 rows\n",
      "Loaded WannaCry.parquet → 14488 rows\n",
      "Loaded Zip.parquet → 18295 rows\n",
      "\n",
      "Combined dataframe shape: (170903, 26)\n",
      "Dropped 'run' column. Columns now: ['family', 'window_id', 'read_throughput', 'read_lba_var', 'write_throughput', 'write_lba_var', 'write_entropy', 'mem_read_count_4k', 'mem_read_count_2m', 'mem_read_count_mmio', 'mem_read_gpa_var', 'mem_write_entropy', 'mem_write_count_4k', 'mem_write_count_2m', 'mem_write_count_mmio', 'mem_write_gpa_var', 'mem_readwrite_entropy', 'mem_readwrite_count_4k', 'mem_readwrite_count_2m', 'mem_readwrite_count_mmio', 'mem_readwrite_gpa_var', 'mem_exec_count_4k', 'mem_exec_count_2m', 'mem_exec_count_mmio', 'mem_exec_gpa_var']\n",
      "\n",
      "Saved final dataset to: ../Datasets/final_dataset.parquet\n"
     ]
    }
   ],
   "source": [
    "FINAL_DATASET_PATH = \"../Datasets/final_dataset.parquet\"\n",
    "\n",
    "parquet_files = [f for f in os.listdir(PROCESSED_PATH) if f.endswith(\".parquet\")]\n",
    "\n",
    "dfs = []\n",
    "for pf in parquet_files:\n",
    "    path = os.path.join(PROCESSED_PATH, pf)\n",
    "    df = pd.read_parquet(path)\n",
    "    dfs.append(df)\n",
    "    print(f\"Loaded {pf} → {df.shape[0]} rows\")\n",
    "\n",
    "final_df = pd.concat(dfs, ignore_index=True)\n",
    "print(\"\\nCombined dataframe shape:\", final_df.shape)\n",
    "\n",
    "final_df = final_df.drop(columns=[\"run\"])\n",
    "print(\"Dropped 'run' column. Columns now:\", final_df.columns.tolist())\n",
    "\n",
    "final_df.to_parquet(FINAL_DATASET_PATH)\n",
    "print(\"\\nSaved final dataset to:\", FINAL_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "919322f0-2c87-4bd7-b7bd-8d0a500075f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset shape: (170903, 25)\n",
      "\n",
      "==== Columns ====\n",
      "['family', 'window_id', 'read_throughput', 'read_lba_var', 'write_throughput', 'write_lba_var', 'write_entropy', 'mem_read_count_4k', 'mem_read_count_2m', 'mem_read_count_mmio', 'mem_read_gpa_var', 'mem_write_entropy', 'mem_write_count_4k', 'mem_write_count_2m', 'mem_write_count_mmio', 'mem_write_gpa_var', 'mem_readwrite_entropy', 'mem_readwrite_count_4k', 'mem_readwrite_count_2m', 'mem_readwrite_count_mmio', 'mem_readwrite_gpa_var', 'mem_exec_count_4k', 'mem_exec_count_2m', 'mem_exec_count_mmio', 'mem_exec_gpa_var']\n",
      "\n",
      "==== Samples per family ====\n",
      "family\n",
      "AESCrypt    19557\n",
      "Zip         18295\n",
      "LockBit     18093\n",
      "Conti       17739\n",
      "SDelete     17332\n",
      "Darkside    16771\n",
      "REvil       15296\n",
      "WannaCry    14488\n",
      "Ryuk        10636\n",
      "Firefox     10042\n",
      "Office       6465\n",
      "Idle         6189\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==== Nulls per column ====\n",
      "family                      0\n",
      "window_id                   0\n",
      "read_throughput             0\n",
      "read_lba_var                0\n",
      "write_throughput            0\n",
      "write_lba_var               0\n",
      "write_entropy               0\n",
      "mem_read_count_4k           0\n",
      "mem_read_count_2m           0\n",
      "mem_read_count_mmio         0\n",
      "mem_read_gpa_var            0\n",
      "mem_write_entropy           0\n",
      "mem_write_count_4k          0\n",
      "mem_write_count_2m          0\n",
      "mem_write_count_mmio        0\n",
      "mem_write_gpa_var           0\n",
      "mem_readwrite_entropy       0\n",
      "mem_readwrite_count_4k      0\n",
      "mem_readwrite_count_2m      0\n",
      "mem_readwrite_count_mmio    0\n",
      "mem_readwrite_gpa_var       0\n",
      "mem_exec_count_4k           0\n",
      "mem_exec_count_2m           0\n",
      "mem_exec_count_mmio         0\n",
      "mem_exec_gpa_var            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(FINAL_DATASET_PATH)\n",
    "print(\"Final dataset shape:\", df.shape)\n",
    "\n",
    "print(\"\\n==== Columns ====\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "print(\"\\n==== Samples per family ====\")\n",
    "print(df[\"family\"].value_counts())\n",
    "\n",
    "print(\"\\n==== Nulls per column ====\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b513aa2c-8b6f-4613-8db9-8cca6cd1d996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dataset with labels to: ../Datasets/final_dataset_with_labels.parquet\n",
      "\n",
      "Label distribution:\n",
      "label\n",
      "1    93023\n",
      "0    77880\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "BENIGN_FAMILIES = [\"AESCrypt\", \"Firefox\", \"Idle\", \"Office\", \"SDelete\", \"Zip\"]\n",
    "FINAL_WITH_LABELS_PATH = \"../Datasets/final_dataset_with_labels.parquet\"\n",
    "\n",
    "df[\"label\"] = df[\"family\"].apply(lambda x: 0 if x in BENIGN_FAMILIES else 1)\n",
    "\n",
    "df.to_parquet(FINAL_WITH_LABELS_PATH)\n",
    "print(\"Saved dataset with labels to:\", FINAL_WITH_LABELS_PATH)\n",
    "\n",
    "print(\"\\nLabel distribution:\")\n",
    "print(df[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0499a511-5488-4305-b297-ae0f53fc6d63",
   "metadata": {},
   "source": [
    "To ensure the robustness and generalization capability of our model, we chose to enrich the benign portion of our dataset with additional samples sourced from other hardware configurations (i3-gen12/ddr4-2666-16g and i3-gen12/ddr4-2133-16g). While our initial dataset provided a balanced representation of ransomware and benign applications, expanding the benign set introduces greater variability in benign behavior patterns. This prevents the model from overfitting to a narrow view of what benign activity looks like, and instead encourages learning more generalized decision boundaries. To maintain balance and avoid bias during training, we will later downsample the expanded benign set to match the ransomware class distribution. This step ensures that our model remains fair while benefiting from a richer and more diverse benign dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "825a5667-6245-4d47-9f8b-faa763b451a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing EXTRA family: Firefox (10 runs)\n",
      "  -> Processing run: Firefox-20230119_20-16-09\n",
      "  -> Processing run: Firefox-20230119_20-22-04\n",
      "  -> Processing run: Firefox-20230119_20-28-00\n",
      "  -> Processing run: Firefox-20230119_20-34-06\n",
      "  -> Processing run: Firefox-20230119_20-39-58\n",
      "  -> Processing run: Firefox-20230119_20-45-40\n",
      "  -> Processing run: Firefox-20230119_20-51-44\n",
      "  -> Processing run: Firefox-20230119_20-57-59\n",
      "  -> Processing run: Firefox-20230119_21-04-02\n",
      "  -> Processing run: Firefox-20230119_21-09-46\n",
      "Saved 10165 windows to ../Datasets/Processed_Extra/Firefox.parquet\n",
      "\n",
      "Processing EXTRA family: Idle (10 runs)\n",
      "  -> Processing run: Idle-20230119_22-46-54\n",
      "  -> Processing run: Idle-20230119_22-52-35\n",
      "  -> Processing run: Idle-20230119_22-58-48\n",
      "  -> Processing run: Idle-20230119_23-04-38\n",
      "  -> Processing run: Idle-20230119_23-10-18\n",
      "  -> Processing run: Idle-20230119_23-16-01\n",
      "  -> Processing run: Idle-20230119_23-22-08\n",
      "  -> Processing run: Idle-20230119_23-28-13\n",
      "  -> Processing run: Idle-20230119_23-33-39\n",
      "  -> Processing run: Idle-20230119_23-39-22\n",
      "Saved 6395 windows to ../Datasets/Processed_Extra/Idle.parquet\n",
      "\n",
      "Processing EXTRA family: Office (10 runs)\n",
      "  -> Processing run: Office-20230118_22-38-29\n",
      "  -> Processing run: Office-20230118_22-44-50\n",
      "  -> Processing run: Office-20230118_22-51-26\n",
      "  -> Processing run: Office-20230118_22-57-31\n",
      "  -> Processing run: Office-20230118_23-03-38\n",
      "  -> Processing run: Office-20230118_23-10-25\n",
      "  -> Processing run: Office-20230118_23-17-13\n",
      "  -> Processing run: Office-20230118_23-24-01\n",
      "  -> Processing run: Office-20230118_23-30-20\n",
      "  -> Processing run: Office-20230118_23-37-02\n",
      "Saved 7003 windows to ../Datasets/Processed_Extra/Office.parquet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "EXTRA_DATASET_PATH = \"../Datasets/RanSMAP/dataset/benign_extra\"\n",
    "PROCESSED_EXTRA_PATH = \"../Datasets/Processed_Extra\"\n",
    "os.makedirs(PROCESSED_EXTRA_PATH, exist_ok=True)\n",
    "\n",
    "for family in families:\n",
    "    family_path = os.path.join(EXTRA_DATASET_PATH, family)\n",
    "    runs = sorted([\n",
    "        r for r in os.listdir(family_path)\n",
    "        if os.path.isdir(os.path.join(family_path, r))\n",
    "    ])\n",
    "\n",
    "    print(f\"\\nProcessing EXTRA family: {family} ({len(runs)} runs)\")\n",
    "    family_rows = []\n",
    "\n",
    "    for run in runs:\n",
    "        run_path = os.path.join(family_path, run)\n",
    "        print(f\"  -> Processing run: {run}\")\n",
    "\n",
    "        run_dfs = []\n",
    "\n",
    "        for csv_file, colnames in csv_files.items():\n",
    "            file_path = os.path.join(run_path, csv_file)\n",
    "\n",
    "            if not os.path.exists(file_path):\n",
    "                continue\n",
    "\n",
    "            df = pd.read_csv(file_path, header=None, names=colnames)\n",
    "            df[\"op_type\"] = csv_file.replace(\".csv\", \"\")\n",
    "            df[\"family\"] = family\n",
    "            df[\"run\"] = run\n",
    "            run_dfs.append(df)\n",
    "\n",
    "        if not run_dfs:\n",
    "            continue\n",
    "\n",
    "        run_df = pd.concat(run_dfs, ignore_index=True)\n",
    "\n",
    "        run_df[\"time\"] = run_df[\"ts\"] + run_df[\"tns\"] * 1e-9\n",
    "        run_df[\"time\"] -= run_df[\"time\"].min()\n",
    "        run_df[\"window\"] = (run_df[\"time\"] // WINDOW_SIZE).astype(int)\n",
    "\n",
    "        for window_id, window_data in run_df.groupby(\"window\"):\n",
    "            row = {\"family\": family, \"run\": run, \"window_id\": window_id}\n",
    "\n",
    "            read = window_data[window_data[\"op_type\"] == \"ata_read\"]\n",
    "            row[\"read_throughput\"] = read[\"size\"].sum() / WINDOW_SIZE\n",
    "            row[\"read_lba_var\"] = read[\"lba\"].var(ddof=0) if not read.empty else 0\n",
    "\n",
    "            write = window_data[window_data[\"op_type\"] == \"ata_write\"]\n",
    "            row[\"write_throughput\"] = write[\"size\"].sum() / WINDOW_SIZE\n",
    "            row[\"write_lba_var\"] = write[\"lba\"].var(ddof=0) if not write.empty else 0\n",
    "            row[\"write_entropy\"] = write[write[\"entropy\"] >= 0][\"entropy\"].mean() if not write.empty else 0\n",
    "\n",
    "            for op in [\"mem_read\", \"mem_write\", \"mem_readwrite\", \"mem_exec\"]:\n",
    "                mem = window_data[window_data[\"op_type\"] == op]\n",
    "                prefix = op\n",
    "\n",
    "                if op in [\"mem_write\", \"mem_readwrite\"]:\n",
    "                    row[f\"{prefix}_entropy\"] = mem[mem[\"entropy\"] >= 0][\"entropy\"].mean() if not mem.empty else 0\n",
    "\n",
    "                for ptype, name in zip([0, 1, 2], [\"4k\", \"2m\", \"mmio\"]):\n",
    "                    row[f\"{prefix}_count_{name}\"] = (mem[\"type\"] == ptype).sum()\n",
    "\n",
    "                row[f\"{prefix}_gpa_var\"] = mem[\"gpa\"].var(ddof=0) if not mem.empty else 0\n",
    "\n",
    "            family_rows.append(row)\n",
    "\n",
    "    family_df = pd.DataFrame(family_rows)\n",
    "    save_path = os.path.join(PROCESSED_EXTRA_PATH, f\"{family}.parquet\")\n",
    "    family_df.to_parquet(save_path)\n",
    "\n",
    "    print(f\"Saved {family_df.shape[0]} windows to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aaf07352-e6e1-4f77-aa89-867836f06dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main dataset: (170903, 26)\n",
      "Loaded extra benign families: 3\n"
     ]
    }
   ],
   "source": [
    "main_df = pd.read_parquet(FINAL_WITH_LABELS_PATH)\n",
    "print(\"Main dataset:\", main_df.shape)\n",
    "\n",
    "extra_files = [f for f in os.listdir(PROCESSED_EXTRA_PATH) if f.endswith(\".parquet\")]\n",
    "extra_dfs = []\n",
    "\n",
    "for f in extra_files:\n",
    "    df = pd.read_parquet(os.path.join(PROCESSED_EXTRA_PATH, f))\n",
    "    df[\"label\"] = 0  \n",
    "    extra_dfs.append(df)\n",
    "\n",
    "print(\"Loaded extra benign families:\", len(extra_dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6b5c550-841d-4250-b6e4-148c772737c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset shape: (194466, 27)\n",
      "label\n",
      "0    101443\n",
      "1     93023\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "full_df = pd.concat([main_df, *extra_dfs], ignore_index=True)\n",
    "print(\"Combined dataset shape:\", full_df.shape)\n",
    "\n",
    "full_df = full_df.drop(columns=[\"run\"])\n",
    "\n",
    "\n",
    "print(full_df[\"label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5796a308-4a10-4079-8d5a-ca08d4c9d313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset shape: (194466, 26)\n",
      "\n",
      "==== Columns ====\n",
      "['family', 'window_id', 'read_throughput', 'read_lba_var', 'write_throughput', 'write_lba_var', 'write_entropy', 'mem_read_count_4k', 'mem_read_count_2m', 'mem_read_count_mmio', 'mem_read_gpa_var', 'mem_write_entropy', 'mem_write_count_4k', 'mem_write_count_2m', 'mem_write_count_mmio', 'mem_write_gpa_var', 'mem_readwrite_entropy', 'mem_readwrite_count_4k', 'mem_readwrite_count_2m', 'mem_readwrite_count_mmio', 'mem_readwrite_gpa_var', 'mem_exec_count_4k', 'mem_exec_count_2m', 'mem_exec_count_mmio', 'mem_exec_gpa_var', 'label']\n",
      "\n",
      "==== Samples per family ====\n",
      "family\n",
      "Firefox     20207\n",
      "AESCrypt    19557\n",
      "Zip         18295\n",
      "LockBit     18093\n",
      "Conti       17739\n",
      "SDelete     17332\n",
      "Darkside    16771\n",
      "REvil       15296\n",
      "WannaCry    14488\n",
      "Office      13468\n",
      "Idle        12584\n",
      "Ryuk        10636\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Final dataset shape:\", full_df.shape)\n",
    "\n",
    "print(\"\\n==== Columns ====\")\n",
    "print(full_df.columns.tolist())\n",
    "\n",
    "print(\"\\n==== Samples per family ====\")\n",
    "print(full_df[\"family\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6759d645-e442-40a5-a3f2-1d944d867358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved final balanced dataset to: ../Datasets/final_dataset_balanced.parquet\n"
     ]
    }
   ],
   "source": [
    "FINAL_DATASET_PATH = \"../Datasets/final_dataset_balanced.parquet\"\n",
    "\n",
    "full_df.to_parquet(FINAL_DATASET_PATH)\n",
    "print(\"Saved final balanced dataset to:\", FINAL_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e91577-e8a1-49a6-a5d7-4eac7de1b83e",
   "metadata": {},
   "source": [
    "\n",
    "# **Final Dataset Overview and Description**\n",
    "\n",
    "The final dataset used for our experiments represents a carefully constructed and balanced collection of ransomware and benign execution patterns captured through low-level memory and storage access traces. The dataset was generated from multiple runs of various ransomware and benign programs executed on monitored machines, where detailed access patterns to storage (SSD) and memory (RAM) were recorded.\n",
    "\n",
    "After an extensive preprocessing pipeline, this dataset was aggregated into fixed time-window based samples, producing a clean, balanced dataset ready for machine learning purposes.\n",
    "\n",
    "### Dataset Dimensions and Structure\n",
    "\n",
    "* **Total samples (rows):** 194,466\n",
    "* **Total features (columns):** 26 (excluding index)\n",
    "* **Class distribution:**\n",
    "\n",
    "  * **Benign (label=0):** 101,443 samples\n",
    "  * **Ransomware (label=1):** 93,023 samples\n",
    "\n",
    "This distribution was achieved after carefully balancing ransomware and benign samples to ensure fair and unbiased model training.\n",
    "\n",
    "---\n",
    "\n",
    "### Families and Sample Counts\n",
    "\n",
    "The samples are distributed across 12 application families, where some represent ransomware and others represent benign software. The per-family distribution is as follows:\n",
    "\n",
    "| Family   | Sample Count |\n",
    "| -------- | ------------ |\n",
    "| Firefox  | 20207        |\n",
    "| AESCrypt | 19557        |\n",
    "| Zip      | 18295        |\n",
    "| LockBit  | 18093        |\n",
    "| Conti    | 17739        |\n",
    "| SDelete  | 17332        |\n",
    "| Darkside | 16771        |\n",
    "| REvil    | 15296        |\n",
    "| WannaCry | 14488        |\n",
    "| Office   | 13468        |\n",
    "| Idle     | 12584        |\n",
    "| Ryuk     | 10636        |\n",
    "\n",
    "Families such as Firefox, Idle, and Office represent benign programs, while the others correspond to ransomware families.\n",
    "\n",
    "---\n",
    "\n",
    "### Sampling Methodology (Time Windows)\n",
    "\n",
    "The dataset is structured using **fixed time windows of 0.1 seconds (100 milliseconds)**.\n",
    "Each sample (row) in the dataset corresponds to **one 0.1-second window** during program execution and aggregates multiple storage and memory operations into summarized statistical features within that period.\n",
    "\n",
    "This approach enables modeling the temporal evolution of program behavior while keeping input features fixed-length and manageable for machine learning models.\n",
    "\n",
    "---\n",
    "\n",
    "### Columns and Feature Definitions\n",
    "\n",
    "Each row in the dataset contains the following columns, representing aggregated statistical features:\n",
    "\n",
    "#### Meta information\n",
    "\n",
    "* **family:** Name of the malware or benign family (e.g., Firefox, LockBit, REvil, etc.)\n",
    "* **window\\_id:** The ID of the time window during execution (integer).\n",
    "* **label:** Ground truth class label → `0` for benign and `1` for ransomware.\n",
    "\n",
    "#### Storage access statistics (SSD)\n",
    "\n",
    "* **read\\_throughput:** Total bytes read within the window, divided by window duration (bytes per second).\n",
    "* **read\\_lba\\_var:** Variance of Logical Block Addresses (LBAs) accessed during read operations (quantifies read locality).\n",
    "* **write\\_throughput:** Total bytes written within the window, divided by window duration (bytes per second).\n",
    "* **write\\_lba\\_var:** Variance of LBAs accessed during write operations (quantifies write locality).\n",
    "* **write\\_entropy:** Average Shannon entropy of written sectors (used to detect encryption behavior typical of ransomware).\n",
    "\n",
    "#### Memory access statistics (RAM)\n",
    "\n",
    "##### Read memory accesses:\n",
    "\n",
    "* **mem\\_read\\_count\\_4k:** Count of read accesses to 4KB memory pages.\n",
    "* **mem\\_read\\_count\\_2m:** Count of read accesses to 2MB memory pages.\n",
    "* **mem\\_read\\_count\\_mmio:** Count of read accesses to MMIO (memory mapped I/O) pages.\n",
    "* **mem\\_read\\_gpa\\_var:** Variance of Guest Physical Addresses (GPAs) accessed during read operations.\n",
    "\n",
    "##### Write memory accesses:\n",
    "\n",
    "* **mem\\_write\\_entropy:** Average Shannon entropy of memory write contents.\n",
    "* **mem\\_write\\_count\\_4k:** Count of write accesses to 4KB memory pages.\n",
    "* **mem\\_write\\_count\\_2m:** Count of write accesses to 2MB memory pages.\n",
    "* **mem\\_write\\_count\\_mmio:** Count of write accesses to MMIO pages.\n",
    "* **mem\\_write\\_gpa\\_var:** Variance of GPAs accessed during write operations.\n",
    "\n",
    "##### Read + Write memory accesses:\n",
    "\n",
    "* **mem\\_readwrite\\_entropy:** Average Shannon entropy of combined read/write memory operations.\n",
    "* **mem\\_readwrite\\_count\\_4k:** Count of read/write accesses to 4KB memory pages.\n",
    "* **mem\\_readwrite\\_count\\_2m:** Count of read/write accesses to 2MB memory pages.\n",
    "* **mem\\_readwrite\\_count\\_mmio:** Count of read/write accesses to MMIO pages.\n",
    "* **mem\\_readwrite\\_gpa\\_var:** Variance of GPAs accessed during read/write operations.\n",
    "\n",
    "##### Execution memory accesses (instruction fetch):\n",
    "\n",
    "* **mem\\_exec\\_count\\_4k:** Count of execution accesses to 4KB memory pages.\n",
    "* **mem\\_exec\\_count\\_2m:** Count of execution accesses to 2MB memory pages.\n",
    "* **mem\\_exec\\_count\\_mmio:** Count of execution accesses to MMIO pages.\n",
    "* **mem\\_exec\\_gpa\\_var:** Variance of GPAs accessed during execution accesses.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "\n",
    "Each row in this dataset thus summarizes the behavioral pattern of the program being executed over a 0.1 second window by aggregating statistics across **storage reads/writes, memory reads/writes/executes, address localities, and entropy metrics**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f554b31b-e9f8-4f13-9b7c-967644c0824e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
